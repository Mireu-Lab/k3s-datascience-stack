---
# ConfigMap: 데이터 라이프사이클 관리 스크립트
apiVersion: v1
kind: ConfigMap
metadata:
  name: data-lifecycle-script
  namespace: default
data:
  data-lifecycle-manager.sh: |
    #!/bin/bash
    # HDFS 데이터 라이프사이클 관리 스크립트
    # Hot (NVME) -> Cold (HDD) -> Archive (GCS)
    
    set -e
    
    # 환경 변수
    NVME_PATH="/mnt/nvme/hdfs-data"
    HDD_PATH="/mnt/hdd/hdfs-data"
    GCS_PATH="/mnt/gcs/hdfs-data"
    
    # 시간 기준 (초 단위)
    HOT_TO_COLD_DAYS=2     # 2일
    COLD_TO_ARCHIVE_DAYS=2  # 추가 2일 (총 4일)
    ARCHIVE_MIN_DAYS=7      # 총 7일 이상된 데이터만 Archive
    
    # 로그 함수
    log() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
    }
    
    # 파일 체크섬 계산
    calculate_checksum() {
        local file="$1"
        sha256sum "$file" | awk '{print $1}'
    }
    
    # Hot -> Cold 마이그레이션
    migrate_hot_to_cold() {
        log "=== Hot -> Cold 마이그레이션 시작 ==="
        
        if [ ! -d "$NVME_PATH" ]; then
            log "Hot 데이터 디렉토리 없음: $NVME_PATH"
            return
        fi
        
        local count=0
        
        find "$NVME_PATH" -type f -mtime +${HOT_TO_COLD_DAYS} | while read -r file; do
            local rel_path="${file#$NVME_PATH/}"
            local cold_file="$HDD_PATH/$rel_path"
            local cold_dir=$(dirname "$cold_file")
            
            # Cold 디렉토리 생성
            mkdir -p "$cold_dir"
            
            # 원본 체크섬 계산
            local original_checksum=$(calculate_checksum "$file")
            log "파일 마이그레이션: $rel_path"
            
            # 파일 복사
            cp -p "$file" "$cold_file"
            
            # 복사본 체크섬 확인
            local copied_checksum=$(calculate_checksum "$cold_file")
            
            if [ "$original_checksum" = "$copied_checksum" ]; then
                log "체크섬 검증 성공: $rel_path"
                # 원본 삭제
                rm "$file"
                log "Hot 데이터 삭제 완료: $rel_path"
                count=$((count + 1))
            else
                log "ERROR: 체크섬 불일치 - $rel_path"
                rm "$cold_file"
            fi
        done
        
        log "Hot -> Cold 마이그레이션 완료: ${count}개 파일"
    }
    
    # Cold -> Archive 마이그레이션
    migrate_cold_to_archive() {
        log "=== Cold -> Archive 마이그레이션 시작 ==="
        
        if [ ! -d "$HDD_PATH" ]; then
            log "Cold 데이터 디렉토리 없음: $HDD_PATH"
            return
        fi
        
        local count=0
        
        find "$HDD_PATH" -type f -mtime +${COLD_TO_ARCHIVE_DAYS} | while read -r file; do
            local rel_path="${file#$HDD_PATH/}"
            local archive_file="$GCS_PATH/$rel_path"
            local archive_dir=$(dirname "$archive_file")
            
            # Archive 디렉토리 생성
            mkdir -p "$archive_dir"
            
            # 원본 체크섬 계산
            local original_checksum=$(calculate_checksum "$file")
            log "파일 아카이빙: $rel_path"
            
            # 파일 복사
            cp -p "$file" "$archive_file"
            
            # 복사본 체크섬 확인
            local copied_checksum=$(calculate_checksum "$archive_file")
            
            if [ "$original_checksum" = "$copied_checksum" ]; then
                log "체크섬 검증 성공: $rel_path"
                # 원본 삭제
                rm "$file"
                log "Cold 데이터 삭제 완료: $rel_path"
                count=$((count + 1))
            else
                log "ERROR: 체크섬 불일치 - $rel_path"
                rm "$archive_file"
            fi
        done
        
        log "Cold -> Archive 마이그레이션 완료: ${count}개 파일"
    }
    
    # Archive 데이터 정리 (선택적)
    cleanup_old_archives() {
        log "=== Archive 데이터 정리 시작 ==="
        
        if [ ! -d "$GCS_PATH" ]; then
            log "Archive 데이터 디렉토리 없음: $GCS_PATH"
            return
        fi
        
        # Archive 데이터는 GCS에 유지 (삭제하지 않음)
        log "Archive 데이터는 GCS에 영구 보관"
    }
    
    # 디렉토리 통계
    print_statistics() {
        log "=== 스토리지 사용 통계 ==="
        
        if [ -d "$NVME_PATH" ]; then
            local hot_count=$(find "$NVME_PATH" -type f 2>/dev/null | wc -l)
            local hot_size=$(du -sh "$NVME_PATH" 2>/dev/null | awk '{print $1}')
            log "Hot (NVME): ${hot_count} 파일, ${hot_size}"
        fi
        
        if [ -d "$HDD_PATH" ]; then
            local cold_count=$(find "$HDD_PATH" -type f 2>/dev/null | wc -l)
            local cold_size=$(du -sh "$HDD_PATH" 2>/dev/null | awk '{print $1}')
            log "Cold (HDD): ${cold_count} 파일, ${cold_size}"
        fi
        
        if [ -d "$GCS_PATH" ]; then
            local archive_count=$(find "$GCS_PATH" -type f 2>/dev/null | wc -l)
            local archive_size=$(du -sh "$GCS_PATH" 2>/dev/null | awk '{print $1}')
            log "Archive (GCS): ${archive_count} 파일, ${archive_size}"
        fi
    }
    
    # 메인 실행
    main() {
        log "========================================="
        log "HDFS 데이터 라이프사이클 관리 시작"
        log "========================================="
        
        # 디렉토리 생성
        mkdir -p "$NVME_PATH" "$HDD_PATH" "$GCS_PATH"
        
        # 현재 상태 출력
        print_statistics
        
        # 마이그레이션 실행
        migrate_hot_to_cold
        migrate_cold_to_archive
        cleanup_old_archives
        
        # 최종 상태 출력
        print_statistics
        
        log "========================================="
        log "데이터 라이프사이클 관리 완료"
        log "========================================="
    }
    
    main "$@"
---
# CronJob: 데이터 라이프사이클 자동화
# 매일 새벽 2시에 실행
apiVersion: batch/v1
kind: CronJob
metadata:
  name: data-lifecycle-manager
  namespace: default
spec:
  schedule: "0 2 * * *"  # 매일 새벽 2시
  concurrencyPolicy: Forbid  # 동시 실행 방지
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          nodeSelector:
            kubernetes.io/hostname: mireu-lab-workstation
          containers:
          - name: data-lifecycle
            image: ubuntu:24.04
            command:
            - /bin/bash
            - /scripts/data-lifecycle-manager.sh
            volumeMounts:
            - name: scripts
              mountPath: /scripts
              readOnly: true
            - name: nvme
              mountPath: /mnt/nvme
            - name: hdd
              mountPath: /mnt/hdd
            - name: gcs
              mountPath: /mnt/gcs
            resources:
              requests:
                memory: "512Mi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "2000m"
          volumes:
          - name: scripts
            configMap:
              name: data-lifecycle-script
              defaultMode: 0755
          - name: nvme
            hostPath:
              path: /mnt/nvme
              type: Directory
          - name: hdd
            hostPath:
              path: /mnt/hdd
              type: Directory
          - name: gcs
            hostPath:
              path: /mnt/gcs
              type: Directory
