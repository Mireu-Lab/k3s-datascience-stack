# Apache Hadoop HDFS Helm Values
# Bitnami Hadoop Chart 사용

nameOverride: "hadoop"
fullnameOverride: "hadoop"

hdfs:
  enabled: true

nameNode:
  replicaCount: 1
  
  persistence:
    enabled: true
    storageClass: "nvme-hot-storage"
    size: 100Gi
    accessModes:
      - ReadWriteOnce

  resources:
    requests:
      memory: "4Gi"
      cpu: "1000m"
    limits:
      memory: "8Gi"
      cpu: "2000m"

  nodeSelector:
    kubernetes.io/hostname: ""  # 실제 노드 호스트명으로 변경

dataNode:
  replicaCount: 1
  
  persistence:
    enabled: true
    storageClass: "nvme-hot-storage"
    size: 800Gi
    accessModes:
      - ReadWriteOnce

  resources:
    requests:
      memory: "8Gi"
      cpu: "2000m"
    limits:
      memory: "16Gi"
      cpu: "4000m"

  nodeSelector:
    kubernetes.io/hostname: ""  # 실제 노드 호스트명으로 변경

# HDFS 설정
configuration:
  coreSite:
    fs.defaultFS: "hdfs://hadoop-namenode:9000"
    hadoop.tmp.dir: "/hadoop/tmp"
    
  hdfsSite:
    dfs.replication: "1"  # 단일 노드이므로 replication 1
    dfs.namenode.name.dir: "file:///hadoop/dfs/name"
    dfs.datanode.data.dir: "file:///hadoop/dfs/data"
    dfs.blocksize: "134217728"  # 128MB
    dfs.namenode.handler.count: "100"
    dfs.datanode.max.transfer.threads: "4096"
    # 큰 파일 지원 (이미지, 비디오 등)
    dfs.namenode.fs-limits.max-blocks-per-file: "10000000"

service:
  type: ClusterIP
  ports:
    namenode:
      web: 9870
      rpc: 9000
    datanode:
      web: 9864
      data: 9866
      ipc: 9867

# 메트릭 수집
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    namespace: monitoring

# 네트워크 정책
networkPolicy:
  enabled: true
  allowExternal: false
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: datascience
      - namespaceSelector:
          matchLabels:
            name: storage
